{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß© Lab 5 ‚Äî Tracing & Resource-Aware Agents with OpenAI SDK\n",
    "\n",
    "### üéØ Goal\n",
    "Learn how to **trace agent workflows** using OpenAI SDK and how to use **resources** as contextual knowledge for your Agentic AI system.\n",
    "\n",
    "**Objectives**\n",
    "- Understand what tracing is and why it matters.\n",
    "- Learn to define and use resources inside an agent.\n",
    "- Compare OpenAI native tracing vs LangSmith tracing.\n",
    "- Observe agent ‚Üí LLM ‚Üí resource ‚Üí tool interactions in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API key loaded ‚Äî ready to trace!\n"
     ]
    }
   ],
   "source": [
    "# ü™ú Step 1 ‚Äî Setup and Configuration\n",
    "from agents import Agent, Runner, function_tool\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "if not os.getenv('OPENAI_API_KEY'):\n",
    "    print('‚ö†Ô∏è Please set your OPENAI_API_KEY environment variable before running.')\n",
    "else:\n",
    "    print('‚úÖ API key loaded ‚Äî ready to trace!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç What is Tracing?\n",
    "Tracing helps you visualize how an agent executes a workflow step-by-step:\n",
    "- Which LLMs were called and with what inputs\n",
    "- Which tools were invoked and their outputs\n",
    "- When resources were used for context\n",
    "\n",
    "It provides a transparent view of the agent‚Äôs reasoning path and decision-making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß† Step 2 ‚Äî Define Tools\n",
    "@function_tool\n",
    "def send_email_tool(recipient: str, subject: str, body: str) -> str:\n",
    "    \"\"\"Simulates sending an email using SendGrid.\"\"\"\n",
    "    return f'üìß Email sent to {recipient} | Subject: {subject} | Body: {body[:60]}...'\n",
    "\n",
    "@function_tool\n",
    "def send_push_tool(message: str) -> str:\n",
    "    \"\"\"Simulates a push notification via Pushover.\"\"\"\n",
    "    return f'üîî Push notification sent: {message[:80]}...'\n",
    "\n",
    "@function_tool\n",
    "def math_tool(expression: str) -> str:\n",
    "    \"\"\"Evaluates a simple math expression safely.\"\"\"\n",
    "    try:\n",
    "        result = eval(expression, {\"__builtins__\": {}})\n",
    "        return f'Result: {result}'\n",
    "    except Exception as e:\n",
    "        return f'Error evaluating expression: {e}'\n",
    "\n",
    "@function_tool\n",
    "def mini_llm_tool(query: str) -> str:\n",
    "    \"\"\"Simulates a small local LLM call (like Ollama).\"\"\"\n",
    "    return f'ü§ñ Mini LLM response: Key insights about {query}.'\n",
    "\n",
    "@function_tool\n",
    "def read_project_scope() -> str:\n",
    "    \"\"\"Reads internal project scope document for agent context.\"\"\"\n",
    "    with open(\"resources/project_scope.txt\", \"r\") as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß© Tool Summary\n",
    "| Tool | Purpose |\n",
    "|------|----------|\n",
    "| `send_email_tool` | Simulates email automation (SendGrid) |\n",
    "| `send_push_tool` | Sends a quick push update (Pushover) |\n",
    "| `math_tool` | Evaluates expressions |\n",
    "| `mini_llm_tool` | Runs a lightweight LLM (Ollama-style) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Resource ready at resources/project_scope.txt\n"
     ]
    }
   ],
   "source": [
    "# üìò Step 3 ‚Äî Define a Resource\n",
    "import os\n",
    "\n",
    "os.makedirs('resources', exist_ok=True)\n",
    "\n",
    "with open('resources/project_scope.txt', 'w') as f:\n",
    "    f.write(\"\"\"\n",
    "Project Name: DPoint AI ‚Äì Agentic AI Training & Workflow Automation Platform\n",
    "\n",
    "Project Scope Overview:\n",
    "DPoint AI is developing a modern Agentic AI training and automation platform designed for students, developers, and enterprise teams. The platform combines Large Language Models, tools, resources, and workflow orchestration to simplify building, testing, and deploying agent-based systems.\n",
    "\n",
    "1. Core Objectives:\n",
    "- Provide a hands-on learning environment to teach users how to build Agentic AI systems.\n",
    "- Enable creation of multi-agent workflows that use tools, resources, and web actions.\n",
    "- Offer real-time tracing and debugging using LangSmith-style observability.\n",
    "- Demonstrate how LLMs interact with files, APIs, browser automation, and custom tools.\n",
    "\n",
    "2. Key Features:\n",
    "- Resource-aware agents that read files (e.g., project scope), retrieve context, and use it in decisions.\n",
    "- Tool execution including browser actions, file operations, API calls, and custom plugins.\n",
    "- Agent-to-agent handoff support for complex workflows.\n",
    "- Built-in workflow tracing for education, demos, and enterprise visibility.\n",
    "- Interactive exercises for:\n",
    "  * LLM grounding\n",
    "  * Prompt engineering\n",
    "  * Multi-step reasoning\n",
    "  * Tool calling\n",
    "  * Debugging/tracing with LangSmith\n",
    "\n",
    "3. Target Users:\n",
    "- Students learning LLMs and Agentic AI\n",
    "- Developers experimenting with agents, tools, and workflows\n",
    "- Enterprise teams exploring automation and internal AI copilots\n",
    "- Educators/trainers teaching modern LLM architectures\n",
    "\n",
    "4. Expected Outcomes:\n",
    "- Faster adoption of Agentic AI concepts in academic and corporate environments.\n",
    "- A reusable training curriculum with labs, example projects, and guided workflows.\n",
    "- A platform that demonstrates:\n",
    "  * How LLM agents consume resources\n",
    "  * How they summarize information\n",
    "  * How they communicate updates (email, push notifications, etc.)\n",
    "\n",
    "5. Business Impact:\n",
    "- Standardizes how teams learn and prototype Agentic AI.\n",
    "- Reduces onboarding time for AI developers.\n",
    "- Enables enterprises to visualize and control LLM workflows with full traceability.\n",
    "- Accelerates development of AI copilots and internal automation tools.\n",
    "    \"\"\")\n",
    "\n",
    "# resource = Resource(\n",
    "#     name='Project Scope',\n",
    "#     path='resources/project_scope.txt',\n",
    "#     description='Context file with DPoint AI project scope and goals.'\n",
    "# )\n",
    "\n",
    "print('‚úÖ Resource ready at resources/project_scope.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìÇ What are Resources?\n",
    "Resources act as knowledge bases for Agents ‚Äî text files, PDFs, or structured data they can consult while reasoning.\n",
    "\n",
    "Here our resource is a project document used for contextual decision making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0caa130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from agents import Resource\n",
    "\n",
    "# resource = Resource(\n",
    "#     name=\"Project Scope\",\n",
    "#     path=\"resources/project_scope.txt\",\n",
    "#     description=\"Context file with DPoint AI project scope and goals.\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "588635c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "file = client.files.create(\n",
    "    file=open(\"resources/project_scope.txt\", \"rb\"),\n",
    "    purpose=\"assistants\" #  ['fine-tune', 'assistants', 'batch', 'user_data', 'vision', 'evals'] \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5288cc9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-U4JtniusYoSJuy3FaWGixG', bytes=2179, created_at=1763186588, filename='project_scope.txt', object='file', purpose='assistants', status='processed', expires_at=None, status_details=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agent created successfully!\n"
     ]
    }
   ],
   "source": [
    "# ‚öôÔ∏è Step 4 ‚Äî Create the Agent\n",
    "agent = Agent(\n",
    "    name='TracingAgent',\n",
    "    # option 1\n",
    "    # instructions='Use the project resource for context before acting. Always explain reasoning before using tools.',\n",
    "    # resources=[resource]\n",
    "\n",
    "    # option 2\n",
    "    # write instruction to use file name \n",
    "    # files=[\"resources/project_scope.txt\"], \n",
    "    # files=['file-U4JtniusYoSJuy3FaWGixG'], #file.id\n",
    "\n",
    "    # option 3\n",
    "    # instruction = \"use this for answering ur questions + {content of file}\" - system prompt\n",
    "    \n",
    "    # option 4\n",
    "    instructions=\"\"\"Call read_project_scope() before doing anything. Use its content to understand the project and summarize it. \n",
    "    Always explain reasoning before using tools.\"\"\",\n",
    "\n",
    "    \n",
    "\n",
    "    model='gpt-4o-mini',\n",
    "    tools=[send_email_tool, send_push_tool, math_tool, mini_llm_tool,read_project_scope]\n",
    ")\n",
    "print('‚úÖ Agent created successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß† Agent Architecture\n",
    "```\n",
    "User ‚Üí Agent ‚Üí LLM ‚Üí Resource ‚Üí Tool 1 / Tool 2 / Tool 3 ‚Üí Output\n",
    "            ‚Ü≥ Tracing Layer monitors each step\n",
    "```\n",
    "üß≠ The **Tracing Layer** captures reasoning, tool calls and resource reads for debug visibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The updates have been successfully sent to the stakeholders:\n",
      "\n",
      "- **Email**: An email detailing the DPoint AI project scope and objectives was sent to stakeholders.\n",
      "- **Push Notification**: A brief update on the project development was also sent via push notification.\n",
      "\n",
      "If you need any further assistance or additional updates, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# üöÄ Step 5 ‚Äî Run the Agent with Tracing\n",
    "from agents import trace\n",
    "\n",
    "prompt = 'Summarize the project scope and send an update to stakeholders via email and push notification.'\n",
    "\n",
    "with trace(workflow_name='Tracing Demo ‚Äî Resources in Action - with openai'):\n",
    "    # result = Runner.run_sync(agent, prompt)\n",
    "    result = await Runner.run(agent, prompt)\n",
    "    print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîé Step 6 ‚Äî Tracing Types\n",
    "### üü¢ OpenAI Native Tracing\n",
    "- Enabled automatically with `with trace()` context.\n",
    "- View traces at üëâ https://platform.openai.com/traces\n",
    "```python\n",
    "with trace(workflow_name='Agent Trace Demo'):\n",
    "    result = Runner.run_sync(agent, user_prompt)\n",
    "```\n",
    "\n",
    "### üîµ LangSmith Tracing (Advanced ‚Äì Lab 6)\n",
    "Add deep observability by enabling environment variables:\n",
    "```bash\n",
    "export LANGCHAIN_TRACING_V2='true'\n",
    "export LANGCHAIN_ENDPOINT='https://api.smith.langchain.com'\n",
    "export LANGCHAIN_API_KEY='your_key_here'\n",
    "export LANGSMITH_PROJECT=''\n",
    "```\n",
    "```python\n",
    "from langsmith import trace\n",
    "with trace('LangSmith Demo'):\n",
    "    result = Runner.run_sync(agent, prompt)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß≠ Tracing Flow Overview\n",
    "1Ô∏è‚É£ User input ‚Üí Agent reasoning\n",
    "2Ô∏è‚É£ Agent references resources\n",
    "3Ô∏è‚É£ LLM processes and plans\n",
    "4Ô∏è‚É£ Tools execute actions (email, push, math)\n",
    "5Ô∏è‚É£ Tracing logs all steps hierarchically\n",
    "\n",
    "```\n",
    "+-------------------------------------------------------------+\n",
    "| TRACE VIEW                                                 |\n",
    "|-------------------------------------------------------------|\n",
    "| User Prompt ‚Üí Agent Reasoning ‚Üí LLM Call ‚Üí Tool Execution |\n",
    "|            ‚Ü≥ Resource Access ‚Üí Final Output               |\n",
    "+-------------------------------------------------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08cf89f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The updates have been successfully sent:\n",
      "\n",
      "- An email was dispatched to the stakeholders with the subject \"DPoint AI Project Update.\"\n",
      "- A push notification was also sent, announcing the exciting advancements in the DPoint AI platform.\n",
      "\n",
      "If there's anything else you need or any other updates to make, just let me know!\n"
     ]
    }
   ],
   "source": [
    "from langsmith import trace\n",
    "\n",
    "prompt = 'Summarize the project scope and send an update to stakeholders via email and push notification.'\n",
    "\n",
    "with trace(\"LangSmith Tracing Demo ‚Äî Resources in Action - lang smith\"):\n",
    "    result = await Runner.run(agent, prompt)\n",
    "    print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèÅ Step 8 ‚Äî Key Takeaways\n",
    "‚úÖ Tracing shows how agents reason and act step by step.\n",
    "‚úÖ Resources ground agents in real-world context.\n",
    "‚úÖ OpenAI Tracing = simple and native; LangSmith = advanced and production-grade.\n",
    "‚úÖ Combining both gives clarity and observability in Agentic AI systems.\n",
    "\n",
    "üéì Next: *Lab 6 ‚Äì Integrate LangSmith Tracing and LangChain Agents!*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
