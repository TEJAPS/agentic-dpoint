{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d1db95a",
   "metadata": {},
   "source": [
    "# üß† Lab 1: Using the OpenAI SDK Directly (Without Frameworks)\n",
    "Welcome to your first **Agentic AI practical lab**!\n",
    "\n",
    "In this notebook, you'll learn how to interact directly with OpenAI's SDK using both:\n",
    "- ‚úÖ The new **Responses API**\n",
    "- ‚úÖ The classic **Chat Completions API**\n",
    "\n",
    "We'll explore parameters like `temperature`, `max_tokens`, and `top_p` to see how they affect outputs.\n",
    "\n",
    "> üí° Make sure your API key is set as an environment variable before starting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1faab9",
   "metadata": {},
   "source": [
    "### Step 1Ô∏è‚É£ ‚Äì Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b1491c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env file if available\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309e4074",
   "metadata": {},
   "source": [
    "### Step 2Ô∏è‚É£ ‚Äì Check the OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94280666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI API Key exists and begins sk-svcac\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f'‚úÖ OpenAI API Key exists and begins {openai_api_key[:8]}')\n",
    "else:\n",
    "    print('‚ùå API Key not set ‚Äì please check your .env or environment variables.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e817d60",
   "metadata": {},
   "source": [
    "### Step 3Ô∏è‚É£ ‚Äì Initialize the OpenAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f624d4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "print('Client initialized successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a922886",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Part A: Using the **New Responses API**\n",
    "\n",
    "This is the modern interface for OpenAI models. It uses `instructions` + `input` instead of chat-style messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604c0a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List comprehensions in Python provide a concise way to create lists. They allow you to generate a new list by applying an expression to each item in a sequence or iterable and optionally filter items based on a condition.\n",
      "\n",
      "### Basic Syntax:\n",
      "\n",
      "```python\n",
      "[expression for item in iterable if condition]\n",
      "```\n",
      "\n",
      "- **expression**: The value to add to the list.\n",
      "- **item**: The current item from the iterable.\n",
      "- **iterable**: A sequence (like a list, tuple, or string) or any other object that can return its elements one at a time.\n",
      "- **condition** (optional): A predicate to filter the items.\n",
      "\n",
      "### Example:\n",
      "\n",
      "Suppose you want to create a list of squares of even numbers from 0 to 9:\n",
      "\n",
      "```python\n",
      "squares_of_even_numbers = [x**2 for x in range(10) if x % 2 == 0]\n",
      "```\n",
      "\n",
      "- **range(10)** generates numbers from 0 to 9.\n",
      "- **if x % 2 == 0** filters out odd numbers, leaving even numbers.\n",
      "- **x** is the current number in the iteration.\n",
      "- **x**\\*\\*2 is the expression to compute the square of the number.\n",
      "\n",
      "The resulting list `squares_of_even_numbers` will be:\n",
      "\n",
      "```python\n",
      "[0, 4, 16, 36, 64]\n",
      "```\n",
      "\n",
      "This approach is both efficient and readable, making list comprehensions a popular choice for list generation in Python.\n"
     ]
    }
   ],
   "source": [
    "prompt = 'Explain what list comprehensions are in Python with an example.'\n",
    "\n",
    "response = client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    instructions='You are a helpful Python instructor.',\n",
    "    input=prompt\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ad0a58",
   "metadata": {},
   "source": [
    "### üî¨ Experiment with Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cee1cb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Temperature 0.2 ---\n",
      "Code flows like a stream,  \n",
      "Indentations guide the way,  \n",
      "Logic weaves its dream.\n",
      "\n",
      "--- Temperature 0.8 ---\n",
      "Code flows like water,  \n",
      "Indentations shape the flow,  \n",
      "Logic intertwines.\n"
     ]
    }
   ],
   "source": [
    "prompt = 'Write a haiku about Python programming.'\n",
    "for temp in [0.2, 0.8]:\n",
    "    res = client.responses.create(\n",
    "        model='gpt-4o-mini',\n",
    "        instructions='You are a poetic assistant.',\n",
    "        input=prompt,\n",
    "        temperature=temp,\n",
    "        max_output_tokens=50\n",
    "    )\n",
    "    print(f'\\n--- Temperature {temp} ---\\n{res.output_text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4a3b68",
   "metadata": {},
   "source": [
    "### üìä Inspect the Response Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7b1bc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gpt-4o-2024-08-06\n",
      "Usage: ResponseUsage(input_tokens=30, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=306, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=336)\n"
     ]
    }
   ],
   "source": [
    "print('Model:', response.model)\n",
    "print('Usage:', response.usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fdb0c4",
   "metadata": {},
   "source": [
    "### üß© Create a Reusable Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e809ffd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The `with` statement in Python simplifies exception handling by encapsulating common preparation and cleanup tasks. It is typically used for resource management, such as file operations. When you use `with`, it ensures that resources are properly acquired and released, even if an error occurs.\n",
      "\n",
      "For example:\n",
      "\n",
      "```python\n",
      "with open('file.txt', 'r') as file:\n",
      "    data = file.read()\n",
      "```\n",
      "\n",
      "In this case, `open()` acquires the file resource, and `file.close()` is automatically called when the block is exited, ensuring the file is properly closed. This enhances code readability and reduces the risk of resource leaks.\n"
     ]
    }
   ],
   "source": [
    "def ask_responses(prompt, temperature=0.7, max_tokens=150):\n",
    "    '''Send a query using the new Responses API.'''\n",
    "    resp = client.responses.create(\n",
    "        model='gpt-4o-mini',\n",
    "        instructions='You are a concise coding tutor.',\n",
    "        input=prompt,\n",
    "        temperature=temperature,\n",
    "        max_output_tokens=max_tokens\n",
    "    )\n",
    "    return resp.output_text\n",
    "\n",
    "print(ask_responses('Summarize what the with statement does in Python.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cffa1b2",
   "metadata": {},
   "source": [
    "## üí¨ Part B: Using the **Classic Chat Completions API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "047002bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Python, decorators are a powerful and expressive tool that allows you to modify or enhance the behavior of functions or methods. A decorator is essentially a function that wraps another function, allowing you to execute code before and/or after the wrapped function runs, without permanently modifying its behavior.\n",
      "\n",
      "### Key Concepts:\n",
      "\n",
      "1. **Function as First-Class Citizens:** In Python, functions are first-class citizens, which means they can be passed around as arguments, returned from other functions, and assigned to variables.\n",
      "\n",
      "2. **Higher-Order Functions:** A decorator is often a higher-order function, which means it takes a function as an argument and returns a new function that typically calls the original function.\n",
      "\n",
      "3. **Syntax Sugar:** Python provides a `@decorator` syntax that acts as syntactic sugar to make applying decorators easier and more readable.\n",
      "\n",
      "### Example:\n",
      "\n",
      "Let's create a simple decorator that logs the execution of a function. \n",
      "\n",
      "```python\n",
      "def logger(func):\n",
      "    def wrapper(*args, **kwargs):\n",
      "        print(f\"Function '{func.__name__}' is called with arguments: {args}, {kwargs}\")\n",
      "        result = func(*args, **kwargs)\n",
      "        print(f\"Function '{func.__name__}' returned: {result}\")\n",
      "        return result\n",
      "    return wrapper\n",
      "\n",
      "@logger\n",
      "def add(a, b):\n",
      "    return a + b\n",
      "\n",
      "@logger\n",
      "def multiply(a, b):\n",
      "    return a * b\n",
      "\n",
      "# Using the decorated functions\n",
      "result_add = add(5, 3)\n",
      "result_multiply = multiply(4, 6)\n",
      "```\n",
      "\n",
      "### Breakdown of the Example:\n",
      "\n",
      "1. **The Decorator Function (`logger`):**\n",
      "   - The `logger` function takes another function (`func`) as an argument and defines an inner function `wrapper`.\n",
      "   - The `wrapper` function will execute some additional code (in this case, logging) before and after the call to the original function.\n",
      "   - It uses `*args` and `**kwargs` to accept any number of positional and keyword arguments.\n",
      "\n",
      "2. **Applying the Decorator:**\n",
      "   - The `@logger` syntax above the `add` and `multiply` functions applies the `logger` decorator to these functions.\n",
      "   - This is equivalent to doing `add = logger(add)` and `multiply = logger(multiply)`.\n",
      "\n",
      "3. **Using the Decorated Functions:**\n",
      "   - When you call `add(5, 3)`, it actually calls the `wrapper` function in the `logger` decorator, which logs the call, calls the original `add` function, logs the result, and returns the result.\n",
      "\n",
      "### Output:\n",
      "When you run the provided code, you would see output similar to:\n",
      "\n",
      "```\n",
      "Function 'add' is called with arguments: (5, 3), {}\n",
      "Function 'add' returned: 8\n",
      "Function 'multiply' is called with arguments: (4, 6), {}\n",
      "Function 'multiply' returned: 24\n",
      "```\n",
      "\n",
      "### Conclusion:\n",
      "Decorators provide a neat way to augment the functionality of your functions with extra behavior, such as logging, enforcing access control, modifying arguments, and more, all while keeping your code clean and readable.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "messages = [\n",
    "    {'role': 'system', 'content': 'You are a friendly Python assistant.'},\n",
    "    {'role': 'user', 'content': 'Explain what decorators are in Python with an example.'}\n",
    "]\n",
    "\n",
    "chat_response = openai.chat.completions.create(\n",
    "    model='gpt-4o-mini',\n",
    "    messages=messages\n",
    ")\n",
    "print(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4ef1bc",
   "metadata": {},
   "source": [
    "### üéõÔ∏è Chat API Parameters Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2727f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Temperature 0.2 ---\n",
      "In the depths of thought, a spiral winds,  \n",
      "A dance of echoes, where logic binds.  \n",
      "Each step a mirror, reflecting the past,  \n",
      "A journey inward, a spell that's cast.  \n",
      "\n",
      "Like whispers in caves, where shadows play,  \n",
      "Each layer unfolds, then fades away.  \n",
      "\n",
      "\n",
      "--- Temperature 0.9 ---\n",
      "In a world where mirrors softly gleam,  \n",
      "Each reflection births another dream.  \n",
      "A spiral dance, both near and far,  \n",
      "Echoes of thought, like a guiding star.  \n",
      "\n",
      "Down the rabbit hole, we weave and wind,  \n",
      "Infinite paths where answers unwind.  \n",
      "Each layer whispers,\n"
     ]
    }
   ],
   "source": [
    "for temp in [0.2, 0.9]:\n",
    "    r = openai.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=[{'role': 'user', 'content': 'Write a short poem about recursion.'}],\n",
    "        temperature=temp,\n",
    "        max_tokens=60\n",
    "    )\n",
    "    print(f'\\n--- Temperature {temp} ---\\n{r.choices[0].message.content}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc5ab4f",
   "metadata": {},
   "source": [
    "### üß© Reusable Function for Chat API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874392a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"lambda_function\": {\n",
      "    \"definition\": \"A lambda function in Python is a small anonymous function defined with the 'lambda' keyword.\",\n",
      "    \"usage\": {\n",
      "      \"single_expression\": \"It can take any number of arguments but can only have one expression.\",\n",
      "      \"inline_functions\": \"Used for creating small, throwaway functions without formally defining them using 'def'.\",\n",
      "      \"functional_programming\": \"Commonly used in functional programming constructs like map(), filter(), and reduce() for concise code.\",\n",
      "      \"event_handling\": \"Useful in scenarios where a function is needed as an argument, such as event handling or callbacks.\"\n",
      "    },\n",
      "    \"example\": \"lambda x: x * 2\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def ask_chat(prompt, temperature=0.7, max_tokens=150):\n",
    "    '''Send a prompt using the Chat Completions API.'''\n",
    "    r = openai.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=[{'role': 'user', 'content': prompt},\n",
    "        {'role': 'user', 'content': f\"{prompt}\\n\\nPlease respond in valid JSON format.\"}],\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        response_format={'type': 'json_object'}\n",
    "    )\n",
    "    return r.choices[0].message.content\n",
    "\n",
    "print(ask_chat('Summarize what a Python lambda function is used for.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b59f60",
   "metadata": {},
   "source": [
    "## üß† Key Takeaways\n",
    "- **Responses API** ‚Üí Modern and simpler (`instructions` + `input`)\n",
    "- **Chat Completions API** ‚Üí Older but still widely supported (`messages`)\n",
    "- Parameters behave identically in both.\n",
    "- Use `Responses API` for new projects.\n",
    "\n",
    "Next Lab ‚Üí *Building simple memory and chaining LLM calls.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
