{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83d\udd27 Manual Tool Integration vs \ud83d\ude80 MCP Server \u2013 Demonstration Notebook\n",
        "This notebook shows **how much effort is needed to build & integrate tools manually**, and how **MCP eliminates all that pain**.\n",
        "\n",
        "We will:\n",
        "1. Build a **manual tool** (Fetch Weather API)\n",
        "2. Show the **integration pain** when using it with different LLM frameworks\n",
        "3. Show the **same tool wrapped as an MCP server**, which becomes instantly reusable\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1\ufe0f\u20e3 Manual Tool \u2013 Build a Weather Fetcher\nThis is how developers normally write tools."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import requests\n",
        "\n",
        "def get_weather(city: str):\n",
        "    url = f\"https://wttr.in/{city}?format=j1\"\n",
        "    data = requests.get(url).json()\n",
        "    return {\n",
        "        \"city\": city,\n",
        "        \"temp\": data['current_condition'][0]['temp_C'],\n",
        "        \"humidity\": data['current_condition'][0]['humidity'],\n",
        "    }\n",
        "\n",
        "get_weather(\"Hyderabad\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2\ufe0f\u20e3 Pain Point \u2013 Using This Tool With Different LLM Frameworks \n",
        "For **every LLM**, you must write a CUSTOM WRAPPER for this tool:\n",
        "- OpenAI tool schema wrapper\n",
        "- Claude tool schema wrapper\n",
        "- LangChain tool wrapper\n",
        "- LangGraph tool node\n",
        "- CrewAI agent tool plugin\n",
        "\n",
        "\u274c Every framework wants tools in different formats.\n",
        "\u274c You maintain 5 wrappers for 1 tool.\n",
        "\u274c Scaling becomes impossible.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example \u2013 OpenAI Tool Wrapper (custom code)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "openai_schema = {\n",
        "    \"name\": \"get_weather\",\n",
        "    \"description\": \"Fetch weather for a city\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\"city\": {\"type\": \"string\"}},\n",
        "        \"required\": [\"city\"],\n",
        "    }\n",
        "}\n",
        "\n",
        "openai_schema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example \u2013 LangChain Wrapper (more boilerplate)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class LCWeatherTool:\n",
        "    name = \"lc_weather\"\n",
        "    description = \"LC tool wrapper\"\n",
        "    \n",
        "    def _run(self, city: str):\n",
        "        return get_weather(city)\n",
        "\n",
        "LCWeatherTool()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud83d\udccc **This duplication is the REAL problem.**\n\n",
        "You build ONE tool\u2026 but you must maintain FIVE wrappers.\n",
        "When you update the tool \u2192 you must update ALL wrappers.\n",
        "This is not scalable.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83d\ude80 3\ufe0f\u20e3 Now the Magic \u2013 MCP Server Version of the SAME Tool\n",
        "An MCP server standardizes:\n",
        "- tool schema\n",
        "- tool discovery\n",
        "- tool invocation\n",
        "- transport (STDIO/SSE)\n",
        "\n",
        "**One server \u2192 all LLMs can use it. No wrappers. No rewrites.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Pseudo-code MCP server definition\n",
        "mcp_tool_schema = {\n",
        "    \"name\": \"get_weather\",\n",
        "    \"description\": \"Get weather via MCP server\",\n",
        "    \"input_schema\": {\"city\": \"string\"},\n",
        "    \"output_schema\": {\n",
        "        \"city\": \"string\",\n",
        "        \"temp\": \"string\",\n",
        "        \"humidity\": \"string\",\n",
        "    }\n",
        "}\n",
        "mcp_tool_schema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udca5 And now ANY LLM can instantly use this tool:\n",
        "- Claude Desktop\n",
        "- OpenAI Agents\n",
        "- Cursor\n",
        "- VSCode MCP Clients\n",
        "- Browser MCP playgrounds\n",
        "\n",
        "All they do is:\n",
        "```\nclient.get_tools()\nclient.call_tool(\"get_weather\", { city: \"Hyderabad\" })\n```\n",
        "\ud83c\udf89 **ZERO wrapper code needed.**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}